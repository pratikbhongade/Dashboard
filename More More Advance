import pyodbc
import pandas as pd
import dash
import dash_bootstrap_components as dbc
from dash import dcc, html
from dash.dependencies import Input, Output, State
from datetime import datetime, timedelta
import os
from PIL import Image
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from io import BytesIO
import time
import win32com.client as win32
from multiprocessing import Process, Queue
import plotly.express as px
import plotly.graph_objects as go
import base64

# Path to your logo image
logo_path = 'C:\\Aspire_Dashboard\\Aspire.png'

# Encode the image to base64
with open(logo_path, 'rb') as f:
    logo_base64 = base64.b64encode(f.read()).decode('ascii')

# List of bank holidays
bank_holidays = [
    "2024-01-01",  # New Year's Day
    "2024-01-15",  # Martin Luther King, Jr. Day
    "2024-05-27",  # Memorial Day
    "2024-06-19",  # Juneteenth National Independence Day
    "2024-07-04",  # Independence Day
    "2024-09-02",  # Labor Day
    "2024-11-28",  # Thanksgiving Day
    "2024-12-25"   # Christmas
]

# Function to get the last business day
def get_last_business_day():
    today = datetime.today()
    if today.weekday() == 0:  # Monday
        last_business_day = today - timedelta(days=3)
    elif today.weekday() == 6:  # Sunday
        last_business_day = today - timedelta(days=2)
    else:  # Any other day (Tuesday to Saturday)
        last_business_day = today - timedelta(days=1)
    
    # Ensure the date is within the current month
    if last_business_day.month != today.month:
        last_business_day = today.replace(day=1) - timedelta(days=1)
        while last_business_day.weekday() >= 5 or last_business_day.strftime('%Y-%m-%d') in bank_holidays:  # Skip weekends and holidays
            last_business_day -= timedelta(days=1)
    
    return last_business_day

# Get the default date
default_date = get_last_business_day().strftime('%Y-%m-%d')

# Function to fetch data
def fetch_data(selected_date):
    conn_str = (
        r'DRIVER={SQL Server};'
        r'SERVER=SDC01ASRSQPD01S\PSQLINST01;'
        r'DATABASE=ASPIRE;'
        r'Trusted_Connection=yes;'
    )
    conn = pyodbc.connect(conn_str)

    query = f"""
    SELECT 
        CASE 
            WHEN DATEPART(hour, JSH.StartTime) < 14 THEN CONVERT(varchar, DATEADD(day, -1, JSH.StartTime), 23) 
            ELSE CONVERT(varchar, JSH.StartTime, 23) 
        END as ProcessingDate, 
        JSJ.JobStreamJoboid as Joboid, 
        JSJ.Name as JobName,
        CONVERT(datetime, JSH.StartTime AT TIME ZONE 'UTC' AT TIME ZONE 'Eastern Standard Time') AS [StartTime], 
        CONVERT(datetime, JSH.EndTime AT TIME ZONE 'UTC' AT TIME ZONE 'Eastern Standard Time') AS [EndTime], 
        JSH.Status, 
        JSH.Message 
    FROM JobStreamTaskHistory JSH
    LEFT JOIN JobStreamTask JST ON JSH.JobStreamTaskOid = JST.JobStreamTaskoid 
    JOIN JobStreamJob JSJ ON JSJ.JobStreamJoboid = JST.JobStreamJoboid
    WHERE 
        CASE 
            WHEN DATEPART(hour, JSH.StartTime) < 14 THEN CONVERT(varchar, DATEADD(day, -1, JSH.StartTime), 23) 
            ELSE CONVERT(varchar, JSH.StartTime, 23) 
        END = '{selected_date}'
    ORDER BY StartTime ASC
    """
    df = pd.read_sql(query, conn)

    query_30_days = """
    SELECT 
        CONVERT(varchar, JSH.StartTime, 23) as ProcessingDate, 
        JSH.Status,
        JSJ.Name as JobName,
        CONVERT(datetime, JSH.StartTime AT TIME ZONE 'UTC' AT TIME ZONE 'Eastern Standard Time') AS [StartTime],
        CONVERT(datetime, JSH.EndTime AT TIME ZONE 'UTC' AT TIME ZONE 'Eastern Standard Time') AS [EndTime],
        JSH.Message
    FROM JobStreamTaskHistory JSH
    LEFT JOIN JobStreamTask JST ON JSH.JobStreamTaskOid = JST.JobStreamTaskoid 
    JOIN JobStreamJob JSJ ON JSJ.JobStreamJoboid = JST.JobStreamJoboid
    WHERE JSH.StartTime >= DATEADD(day, -30, GETDATE())
    """
    df_30_days = pd.read_sql(query_30_days, conn)

    query_6_months = """
    SELECT 
        CONVERT(varchar, JSH.StartTime, 23) as ProcessingDate, 
        JSJ.Name as JobName,
        CONVERT(datetime, JSH.EndTime AT TIME ZONE 'UTC' AT TIME ZONE 'Eastern Standard Time') AS [EndTime]
    FROM JobStreamTaskHistory JSH
    LEFT JOIN JobStreamTask JST ON JSH.JobStreamTaskOid = JST.JobStreamTaskoid 
    JOIN JobStreamJob JSJ ON JSJ.JobStreamJoboid = JST.JobStreamJoboid
    WHERE JSH.StartTime >= DATEADD(month, -6, GETDATE())
    AND (JSJ.Name = '18. TRIAD' OR JSJ.Name = '20. Benchmark Update')
    ORDER BY ProcessingDate, JSJ.Name
    """
    df_6_months = pd.read_sql(query_6_months, conn)

    query_job_duration = """
    SELECT 
        CONVERT(varchar, JSH.StartTime, 23) as ProcessingDate, 
        JSJ.Name as JobName,
        DATEDIFF(SECOND, JSH.StartTime, JSH.EndTime) / 60.0 as DurationMinutes
    FROM JobStreamTaskHistory JSH
    LEFT JOIN JobStreamTask JST ON JSH.JobStreamTaskOid = JST.JobStreamTaskoid 
    JOIN JobStreamJob JSJ ON JSJ.JobStreamJoboid = JST.JobStreamJoboid
    WHERE JSH.StartTime >= DATEADD(month, -6, GETDATE())
    """
    df_job_duration = pd.read_sql(query_job_duration, conn)

    conn.close()

    return df, df_30_days, df_6_months, df_job_duration

# Fetch initial data
df, df_30_days, df_6_months, df_job_duration = fetch_data(default_date)

# Initialize the Dash app with Bootstrap CSS
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# Layout of the dashboard
app.layout = dbc.Container([
    dbc.Row([
        dbc.Col(html.Img(src='data:image/png;base64,{}'.format(logo_base64), height='60px'), width='auto'),
        dbc.Col(html.H1("ASPIRE DASHBOARD", className='text-center mb-4', style={'font-weight': 'bold', 'color': '#2A3F5F', 'border-bottom': '1px solid #2A3F5F'}), width=True, className='d-flex justify-content-center align-items-center'),
        dbc.Col([
            html.Div("Pick a date ðŸ“†", className='text-center mb-2', style={'font-weight': 'bold'}),
            dcc.DatePickerSingle(
                id='date-picker-table',
                display_format='YYYY-MM-DD',
                date=default_date,  # Default date
                className='form-control',
                style={'font-weight': 'bold'}
            )
        ], width='auto', className='d-flex justify-content-end align-items-center')
    ], className='border mb-3 align-items-center'),
    dcc.Markdown(f'''
    <style>
        .DatePickerSingle .DateInput_input, .DateInput_input {
            font-weight: bold;
        }
        .DatePickerSingle .CalendarDay__highlighted_calendar, .CalendarDay__highlighted_calendar {
            background: #2196F3;
            color: white;
        }
        .DatePickerSingle .CalendarDay__highlighted_calendar:hover, .CalendarDay__highlighted_calendar:hover {
            background: #1976D2;
            color: white;
        }
    </style>
    '''),
    dbc.Tabs([
        dbc.Tab(label='Main Dashboard', tab_id='main-dashboard', children=[
            dbc.Row([
                dbc.Col([
                    dbc.Card(
                        dbc.CardBody([
                            html.H4("ASPIRE UNLOCK ONLINE", className='card-title'),
                            html.Div(id='benchmark-update-table')
                        ]),
                        className='mb-4 border'
                    )
                ], width=12)
            ], className='border mb-3'),
            dbc.Row([
                dbc.Col([
                    dcc.Dropdown(
                        id='job-name-dropdown',
                        options=[],
                        placeholder="Select a Job Name",
                        className='mb-4'
                    )
                ], width=6),
                dbc.Col([
                    dcc.Dropdown(
                        id='status-dropdown',
                        options=[],
                        placeholder="Select Job Status",
                        className='mb-4'
                    )
                ], width=6)
            ], className='border mb-3'),
            dbc.Row([
                dbc.Col([
                    html.Div(id='job-table-container')
                ], width=12)
            ], className='border'),
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='status-bar-graph')
                ], width=12)
            ], className='border'),
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='failure-trend-graph')
                ], width=12)
            ], className='border'),
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='time-difference-graph')
                ], width=12)
            ], className='border'),
            dbc.Row([
                dbc.Col([
                    html.Button("Send Email", id="send-email-button", className="btn btn-primary mt-3")
                ], width=12, className='d-flex justify-content-center')
            ], className='border mt-3')
        ]),
        dbc.Tab(label='Job Duration Analysis', tab_id='job-duration', children=[
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='job-duration-graph')
                ], width=12)
            ], className='border mt-3')
        ]),
        dbc.Tab(label='Job Failure Rate', tab_id='job-failure-rate', children=[
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='job-failure-rate-graph')
                ], width=12)
            ], className='border mt-3')
        ]),
        dbc.Tab(label='Performance Metrics', tab_id='performance-metrics', children=[
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='performance-metrics-graph')
                ], width=12)
            ], className='border mt-3')
        ]),
        dbc.Tab(label='Heatmap of Job Runs', tab_id='heatmap-job-runs', children=[
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='heatmap-job-runs-graph')
                ], width=12)
            ], className='border mt-3')
        ]),
        dbc.Tab(label='Anomaly Detection', tab_id='anomaly-detection', children=[
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='anomaly-detection-graph')
                ], width=12)
            ], className='border mt-3')
        ]),
        dbc.Tab(label='Correlation Analysis', tab_id='correlation-analysis', children=[
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='correlation-analysis-graph')
                ], width=12)
            ], className='border mt-3')
        ]),
        dbc.Tab(label='Time to Recovery', tab_id='time-to-recovery', children=[
            dbc.Row([
                dbc.Col([
                    dcc.Graph(id='time-to-recovery-graph')
                ], width=12)
            ], className='border mt-3')
        ])
    ]),
    dcc.ConfirmDialog(
        id='confirm-dialog',
        message='Email sent successfully!',
    ),
], fluid=True, className='p-4 bg-light rounded-3 shadow')

# CSS styling for the date picker input to make it bold
app.css.append_css({
    'external_url': 'https://codepen.io/chriddyp/pen/bWLwgP.css'
})
app.index_string = '''
<!DOCTYPE html>
<html>
    <head>
        {%metas%}
        <title>{%title%}</title>
        {%favicon%}
        {%css%}
        <style>
            .DateInput_input {
                font-weight: bold;
            }
            .DateInput_input {
                font-weight: bold;
            }
            .DatePickerSingle .CalendarDay__highlighted_calendar, .CalendarDay__highlighted_calendar {
                background: #2196F3;
                color: white;
            }
            .DatePickerSingle .CalendarDay__highlighted_calendar:hover, .CalendarDay__highlighted_calendar:hover {
                background: #1976D2;
                color: white;
            }
        </style>
    </head>
    <body>
        {%app_entry%}
        <footer>
            {%config%}
            {%scripts%}
            {%renderer%}
        </footer>
    </body>
</html>
'''

# Callback to update the tables and dropdowns based on the selected date
@app.callback(
    [Output('benchmark-update-table', 'children'),
     Output('job-name-dropdown', 'options'),
     Output('status-dropdown', 'options'),
     Output('job-table-container', 'children'),
     Output('status-bar-graph', 'figure'),
     Output('failure-trend-graph', 'figure'),
     Output('time-difference-graph', 'figure'),
     Output('job-duration-graph', 'figure'),
     Output('job-failure-rate-graph', 'figure'),
     Output('performance-metrics-graph', 'figure'),
     Output('heatmap-job-runs-graph', 'figure'),
     Output('anomaly-detection-graph', 'figure'),
     Output('correlation-analysis-graph', 'figure'),
     Output('time-to-recovery-graph', 'figure')],
    [Input('date-picker-table', 'date'),
     Input('job-name-dropdown', 'value'),
     Input('status-dropdown', 'value')]
)
def update_dashboard(selected_date, selected_job, selected_status):
    print(f"Selected date: {selected_date}")
    
    # Check if the selected date is today and current time is before 9 PM, or if the selected date is in the future
    now = datetime.now()
    if (selected_date == now.strftime('%Y-%m-%d') and now.hour < 21) or datetime.strptime(selected_date, '%Y-%m-%d') > now:
        message = html.Div(
            [
                html.H4("Batch yet to start", className='text-center text-danger')
            ]
        )
        empty_fig = px.bar()
        return message, [], [], message, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig

    if selected_date in bank_holidays or datetime.strptime(selected_date, '%Y-%m-%d').weekday() >= 5:
        message = html.Div(
            [
                html.H4("No data available due to holiday", className='text-center text-danger')
            ]
        )
        empty_fig = px.bar()
        return message, [], [], message, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig

    df, df_30_days, df_6_months, df_job_duration = fetch_data(selected_date)
    
    print(f"Dataframe df empty: {df.empty}")
    print(f"Dataframe df_30_days empty: {df_30_days.empty}")
    print(f"Dataframe df_6_months empty: {df_6_months.empty}")
    print(f"Dataframe df_job_duration empty: {df_job_duration.empty}")

    if df.empty:
        message = html.Div(
            [
                html.H4("No Data Available", className='text-center text-danger')
            ]
        )
        empty_fig = px.bar()
        return message, [], [], message, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig, empty_fig

    df['StartDate'] = pd.to_datetime(df['StartTime']).dt.strftime('%Y-%m-%d')
    df['StartTime'] = pd.to_datetime(df['StartTime']).dt.strftime('%I:%M:%S %p')
    df['EndDate'] = pd.to_datetime(df['EndTime']).dt.strftime('%Y-%m-%d')
    df['EndTime'] = pd.to_datetime(df['EndTime']).dt.strftime('%I:%M:%S %p')

    benchmark_update_df = df[df['JobName'] == '20. Benchmark Update'].copy()
    benchmark_update_df.loc[:, 'JobName'] = benchmark_update_df['JobName'].str.replace('20. ', '', regex=True)
    other_jobs_df = df[df['JobName'] != '20. Benchmark Update']

    benchmark_update_table = dbc.Table.from_dataframe(benchmark_update_df[['JobName', 'StartDate', 'StartTime', 'EndDate', 'EndTime', 'Status']], striped=True, bordered=True, hover=True, className='table-dark')
    
    job_name_options = [{'label': job.replace('20. ', ''), 'value': job} for job in other_jobs_df['JobName'].unique()]
    job_status_options = [{'label': status, 'value': status} for status in other_jobs_df['Status'].unique()]

    filtered_df = other_jobs_df
    if selected_job:
        filtered_df = filtered_df[filtered_df['JobName'] == selected_job]
    if selected_status:
        filtered_df = filtered_df[filtered_df['Status'] == selected_status]

    job_table_header = [html.Thead(html.Tr([html.Th(col) for col in ['JobName', 'StartDate', 'StartTime', 'EndDate', 'EndTime', 'Status']], className='bg-primary text-white'))]
    job_table_body = [html.Tbody([html.Tr([html.Td(filtered_df.iloc[i][col]) for col in ['JobName', 'StartDate', 'StartTime', 'EndDate', 'EndTime', 'Status']]) for i in range(len(filtered_df))])]

    job_table = dbc.Table(job_table_header + job_table_body, striped=True, bordered=True, hover=True)

    status_counts = df['Status'].value_counts().reset_index()
    status_counts.columns = ['Status', 'Count']

    # Customize the bar graph for Job Status Counts
    fig_status = go.Figure(data=[
        go.Bar(
            x=status_counts['Count'],
            y=status_counts['Status'],
            orientation='h',
            marker=dict(
                color=status_counts['Status'].apply(lambda x: 'green' if x == 'Succeeded' else 'orange' if x == 'Succeeded with Exceptions' else 'red'),
                line=dict(color='black', width=1)  # Keep the border
            )
        )
    ])
    fig_status.update_layout(
        title='Job Status Counts',
        xaxis_title='Count',
        yaxis_title='Status',
        template='plotly_white',
        plot_bgcolor='rgba(229,236,246,1)',
        title_font=dict(size=21, family='Arial, bold', color='rgba(42, 63, 95, 1)'),
        xaxis=dict(
            showgrid=True,
            showline=False,
            linewidth=1,
            linecolor='black',
            mirror=True,
            gridcolor='lightgrey'
        ),
        yaxis=dict(
            showgrid=True,
            showline=False,
            linewidth=1,
            linecolor='black',
            mirror=True,
            gridcolor='lightgrey',
        ),
        font=dict(size=14),
        bargap=0.4  # Adjust this value to reduce the height of the bars
    )

    df_30_days['ProcessingDate'] = pd.to_datetime(df_30_days['ProcessingDate'])
    df_30_days['DurationMinutes'] = (df_30_days['EndTime'] - df_30_days['StartTime']).dt.total_seconds() / 60.0
    df_failed = df_30_days[df_30_days['Status'] == 'Failed']
    failure_trend = df_failed.groupby(['ProcessingDate', 'JobName', 'StartTime', 'Message']).size().reset_index(name='Count')
    fig_trend = px.bar(failure_trend, x='ProcessingDate', y='Count', color='JobName', title='Failure Trend Over the Last 30 Days', 
                       hover_data={'StartTime': True, 'JobName': True, 'Message': True})

    triad_df = df_6_months[df_6_months['JobName'] == '18. TRIAD']
    benchmark_update_df = df_6_months[df_6_months['JobName'] == '20. Benchmark Update']

    # Ensure there is data to merge
    if not triad_df.empty and not benchmark_update_df.empty:
        merged_df = pd.merge(triad_df, benchmark_update_df, on='ProcessingDate', suffixes=('_TRIAD', '_Benchmark'))
        merged_df['TimeDifference'] = (merged_df['EndTime_Benchmark'] - merged_df['EndTime_TRIAD']).dt.total_seconds() / 3600

        fig_time_diff = px.line(merged_df, x='ProcessingDate', y='TimeDifference', title='Time Difference between TRIAD and Benchmark Update Jobs Over the Last 6 Months')
    else:
        print("One or both of the dataframes are empty:")
        print(f"TRIAD dataframe empty: {triad_df.empty}")
        print(f"Benchmark Update dataframe empty: {benchmark_update_df.empty}")
        fig_time_diff = px.line(title='No data available for TRIAD or Benchmark Update jobs.')

    # Calculate average job duration per job
    df_job_duration['ProcessingDate'] = pd.to_datetime(df_job_duration['ProcessingDate'])
    avg_duration = df_job_duration.groupby(['ProcessingDate', 'JobName'])['DurationMinutes'].mean().reset_index()
    fig_job_duration = px.line(avg_duration, x='ProcessingDate', y='DurationMinutes', color='JobName', title='Average Job Duration Over Time')

    # Calculate job failure rate
    df_30_days['StatusBinary'] = df_30_days['Status'].apply(lambda x: 1 if x == 'Failed' else 0)
    failure_rate = df_30_days.groupby('ProcessingDate')['StatusBinary'].mean().reset_index()
    failure_rate['FailureRate'] = failure_rate['StatusBinary'] * 100
    fig_failure_rate = px.line(failure_rate, x='ProcessingDate', y='FailureRate', title='Job Failure Rate Over Time')

    # Performance metrics comparison
    performance_metrics = df_30_days.groupby('JobName').agg(
        AvgDuration=('DurationMinutes', 'mean'),
        SuccessRate=('StatusBinary', lambda x: (1 - x.mean()) * 100),
        Frequency=('JobName', 'count')
    ).reset_index()
    fig_performance_metrics = px.box(performance_metrics.melt(id_vars='JobName'), x='JobName', y='value', color='variable', title='Performance Metrics Comparison')

    # Heatmap of job runs
    df_30_days['Hour'] = df_30_days['StartTime'].dt.hour
    df_30_days['Weekday'] = df_30_days['StartTime'].dt.weekday
    heatmap_data = df_30_days.groupby(['Weekday', 'Hour']).size().reset_index(name='JobCount')
    heatmap_data_pivot = heatmap_data.pivot('Weekday', 'Hour', 'JobCount').fillna(0)
    fig_heatmap = px.imshow(heatmap_data_pivot, title='Heatmap of Job Runs')

    # Anomaly detection (using z-score)
    df_30_days['DurationZScore'] = (df_30_days['DurationMinutes'] - df_30_days['DurationMinutes'].mean()) / df_30_days['DurationMinutes'].std()
    anomalies = df_30_days[df_30_days['DurationZScore'].abs() > 2]
    fig_anomaly_detection = px.scatter(anomalies, x='StartTime', y='DurationMinutes', color='JobName', title='Anomaly Detection in Job Durations')

    # Correlation analysis
    correlation_data = df_30_days[['DurationMinutes', 'StatusBinary']]
    fig_correlation = px.scatter_matrix(correlation_data, title='Correlation Analysis of Job Metrics')

    # Time to recovery from failures
    df_30_days['RecoveryTime'] = df_30_days.groupby('JobName')['EndTime'].diff().dt.total_seconds() / 3600
    recovery_data = df_30_days[df_30_days['Status'] == 'Failed'].groupby('ProcessingDate')['RecoveryTime'].mean().reset_index()
    fig_recovery = px.bar(recovery_data, x='ProcessingDate', y='RecoveryTime', title='Time to Recovery from Job Failures')

    return benchmark_update_table, job_name_options, job_status_options, job_table, fig_status, fig_trend, fig_time_diff, fig_job_duration, fig_failure_rate, fig_performance_metrics, fig_heatmap, fig_anomaly_detection, fig_correlation, fig_recovery

def run_dash_app(queue):
    print("Starting Dash app...")
    app.run_server(debug=True, port=8050, use_reloader=False)
    print("Dash app stopped.")
    queue.put("Dash app stopped")

def run_dashboard():
    queue = Queue()
    dash_process = Process(target=run_dash_app, args=(queue,))
    dash_process.start()

    # Give the server some time to start
    time.sleep(10)  # Increased wait time to ensure the server starts

    # Set up Selenium WebDriver for Chrome (ensure you have a compatible Chrome WebDriver in PATH)
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")  # Increase window size for full capture

    chrome_driver_path = "C:\\chromedriver_win64\\chromedriver.exe"
    print(f"Using ChromeDriver from: {chrome_driver_path}")

    webdriver_service = ChromeService(executable_path=chrome_driver_path)
    try:
        driver = webdriver.Chrome(service=webdriver_service, options=chrome_options)
    except Exception as e:
        print(f"Error initializing Chrome WebDriver: {e}")
        raise

    # Open the Dash app in the browser
    print("Opening Dash app in Chrome browser...")
    driver.get("http://127.0.0.1:8050/")
    time.sleep(5)  # Give some time to ensure the page loads

    return driver, dash_process, queue

def capture_full_page_screenshot(driver, file_path):
    # Get the dimensions of the page
    total_width = driver.execute_script("return document.body.scrollWidth")
    total_height = driver.execute_script("return document.body.scrollHeight")
    viewport_height = driver.execute_script("return window.innerHeight")

    # Set the browser window to the total page width
    driver.set_window_size(total_width, viewport_height)
    time.sleep(2)  # Allow time for the window resize to take effect

    # List to hold individual screenshots
    screenshots = []

    # Scroll and capture screenshots
    for i in range(0, total_height, viewport_height):
        if i + viewport_height > total_height:
            viewport_height = total_height - i
            driver.execute_script(f"window.scrollTo(0, {i});")
            time.sleep(1)
            driver.set_window_size(total_width, viewport_height)
        else:
            driver.execute_script(f"window.scrollTo(0, {i});")
            time.sleep(1)
        
        screenshot = driver.get_screenshot_as_png()
        screenshots.append(Image.open(BytesIO(screenshot)))

    # Stitch screenshots together
    stitched_image = Image.new('RGB', (total_width, total_height))
    y_offset = 0
    for screenshot in screenshots:
        stitched_image.paste(screenshot, (0, y_offset))
        y_offset += screenshot.size[1]

    stitched_image.save(file_path)

def send_email_with_screenshot(image_path, processing_date, benchmark_end_time):
    # Send an email with the screenshot embedded
    outlook = win32.Dispatch('outlook.application')
    mail = outlook.CreateItem(0)
    mail.To = 'Pratik_Bhongade@Keybank.com'
    mail.Subject = 'Aspire Dashboard'
    
    with open(image_path, 'rb') as f:
        image_data = f.read()
        image_cid = 'dashboard_image'
    
    mail.HTMLBody = f'''
    <p>Hi All,</p>
    <p>Please find the status of Aspire Nightly Batch - <strong>{processing_date}</strong></p>
    <p><strong>Highlight:</strong></p>
    <ul>
        <li>Aspire Online Availability at <strong>{benchmark_end_time}</strong></li>
    </ul>
    <p><u><strong>ASPIRE DASHBOARD</strong></u>:</p>
    <img src="cid:{image_cid}" width="800">
    <p>Thanks,</p>
    <p>Pratik Bhongade<br>
    Jr. Software Engineer<br>
    Pune, India<br>
    KEF<br>
    Pratik_Bhongade@key.com</p>
    '''

    attachment = mail.Attachments.Add(image_path)
    attachment.PropertyAccessor.SetProperty("http://schemas.microsoft.com/mapi/proptag/0x3712001F", image_cid)

    mail.Send()

    print("Email sent with the dashboard image embedded.")

@app.callback(
    [Output('send-email-button', 'n_clicks'), Output('confirm-dialog', 'displayed')],
    [Input('send-email-button', 'n_clicks')],
    [State('date-picker-table', 'date')]
)
def handle_send_email(n_clicks, selected_date):
    if n_clicks is not None:
        driver, dash_process, queue = run_dashboard()

        # Capture the full page screenshot
        image_path = r"C:\Aspire_Dashboard\dashboard.png"
        os.makedirs(os.path.dirname(image_path), exist_ok=True)
        capture_full_page_screenshot(driver, image_path)

        # Get the last business day and benchmark end time
        processing_date = selected_date
        benchmark_end_time = df[df['JobName'] == '20. Benchmark Update']['EndTime'].max()

        # Send the email with the screenshot
        send_email_with_screenshot(image_path, processing_date, benchmark_end_time)

        # Close the browser and stop the Dash app
        driver.quit()
        dash_process.terminate()

        return None, True  # Trigger the confirm dialog

    return None, False

def main():
    driver, dash_process, queue = run_dashboard()

    print("Dashboard is running. Press Ctrl+C to stop.")
    try:
        while True:
            if not queue.empty():
                message = queue.get()
                if message == "Dash app stopped":
                    break
            time.sleep(1)
    except KeyboardInterrupt:
        pass

if __name__ == '__main__':
    main()
